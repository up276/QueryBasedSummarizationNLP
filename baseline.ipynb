{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline model: CBOW + MLP classifier\n",
    "\n",
    "We build here our first baseline model which is the following :\n",
    "\n",
    "Load embeddings (already processed):\n",
    "- individual words embedded using word2vec pretrained embeddings \n",
    "- CBOW was used to get query / paragraphs vector representations out of the words vectors (try with tf-idf weighted average)\n",
    "\n",
    "Compare:\n",
    "- similarity learning (bilinar): learn matrix W through computation of query.W.paragraphT\n",
    "\n",
    "Classify :\n",
    "- use final softmax to output probability prediction\n",
    "\n",
    "Code used inspired from:\n",
    "- http://www.erogol.com/duplicate-question-detection-deep-learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'ascii' codec can't decode byte 0x92 in position 4: ordinal not in range(128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-e4d4959c4275>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# load data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m\"../data/fold0_with_wrong_with_CBOW_embeddings\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'ascii' codec can't decode byte 0x92 in position 4: ordinal not in range(128)"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# load data\n",
    "df = pickle.load( open( \"../data/fold0_with_wrong_with_CBOW_embeddings\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pagename</th>\n",
       "      <th>section</th>\n",
       "      <th>para_id</th>\n",
       "      <th>para_text</th>\n",
       "      <th>rel_label</th>\n",
       "      <th>query</th>\n",
       "      <th>query_CBOW</th>\n",
       "      <th>paragraph_CBOW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>530192</th>\n",
       "      <td>queensland air museum</td>\n",
       "      <td>aircraft on display</td>\n",
       "      <td>90fdae09838530d8001220d0c963594c74b3c0c7</td>\n",
       "      <td>As of March 2014.</td>\n",
       "      <td>1</td>\n",
       "      <td>aircraft on display of queensland air museum</td>\n",
       "      <td>[2.54523002729, 0.987329989672, 1.39032000676,...</td>\n",
       "      <td>[1.04178700969, 0.649680987, 0.633059997112, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77501</th>\n",
       "      <td>background of the occupation of the baltic states</td>\n",
       "      <td>europe becomes unstable</td>\n",
       "      <td>721ee539577c3a2c9e75ff393422edf619bde41b</td>\n",
       "      <td>The Soviet Union remained conciliatory with Ba...</td>\n",
       "      <td>1</td>\n",
       "      <td>europe becomes unstable of background of the o...</td>\n",
       "      <td>[-0.53776698187, 0.524886905681, -0.5034700036...</td>\n",
       "      <td>[8.48787346703, 9.09795231628, -1.21728977765,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198858</th>\n",
       "      <td>dirt track racing 2</td>\n",
       "      <td>game modes</td>\n",
       "      <td>2f5b10ded43062a7f40df8357e4a67d431e7a5dc</td>\n",
       "      <td>Multiplayer allows you to race against up to n...</td>\n",
       "      <td>1</td>\n",
       "      <td>game modes of dirt track racing 2</td>\n",
       "      <td>[2.04991998896, 0.849495004863, -1.66701780166...</td>\n",
       "      <td>[-0.69690399617, -0.88491801545, -2.5799840046...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195387</th>\n",
       "      <td>dexter walker</td>\n",
       "      <td>storylines</td>\n",
       "      <td>6d3a3149cfc492f79dff3330124d6ab39a9ddea5</td>\n",
       "      <td>Dex is diagnosed with a brain injury  leaving ...</td>\n",
       "      <td>1</td>\n",
       "      <td>storylines of dexter walker</td>\n",
       "      <td>[-0.72718001157, 0.303549099248, 0.10183998569...</td>\n",
       "      <td>[2.70971485808, 24.6431179714, -21.5583597224,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177888</th>\n",
       "      <td>criminal record</td>\n",
       "      <td>united kingdom</td>\n",
       "      <td>f16b0995653bd249a5d71934cae333befa7246fb</td>\n",
       "      <td>Information supplied depends on the level of d...</td>\n",
       "      <td>1</td>\n",
       "      <td>united kingdom of criminal record</td>\n",
       "      <td>[-0.390038985759, 0.0567329889163, 0.371367026...</td>\n",
       "      <td>[-3.37157545811, 5.95376241195, -9.73813020345...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 pagename  \\\n",
       "530192                              queensland air museum   \n",
       "77501   background of the occupation of the baltic states   \n",
       "198858                                dirt track racing 2   \n",
       "195387                                      dexter walker   \n",
       "177888                                    criminal record   \n",
       "\n",
       "                        section                                   para_id  \\\n",
       "530192      aircraft on display  90fdae09838530d8001220d0c963594c74b3c0c7   \n",
       "77501   europe becomes unstable  721ee539577c3a2c9e75ff393422edf619bde41b   \n",
       "198858               game modes  2f5b10ded43062a7f40df8357e4a67d431e7a5dc   \n",
       "195387               storylines  6d3a3149cfc492f79dff3330124d6ab39a9ddea5   \n",
       "177888           united kingdom  f16b0995653bd249a5d71934cae333befa7246fb   \n",
       "\n",
       "                                                para_text  rel_label  \\\n",
       "530192                                  As of March 2014.          1   \n",
       "77501   The Soviet Union remained conciliatory with Ba...          1   \n",
       "198858  Multiplayer allows you to race against up to n...          1   \n",
       "195387  Dex is diagnosed with a brain injury  leaving ...          1   \n",
       "177888  Information supplied depends on the level of d...          1   \n",
       "\n",
       "                                                    query  \\\n",
       "530192       aircraft on display of queensland air museum   \n",
       "77501   europe becomes unstable of background of the o...   \n",
       "198858                  game modes of dirt track racing 2   \n",
       "195387                        storylines of dexter walker   \n",
       "177888                  united kingdom of criminal record   \n",
       "\n",
       "                                               query_CBOW  \\\n",
       "530192  [2.54523002729, 0.987329989672, 1.39032000676,...   \n",
       "77501   [-0.53776698187, 0.524886905681, -0.5034700036...   \n",
       "198858  [2.04991998896, 0.849495004863, -1.66701780166...   \n",
       "195387  [-0.72718001157, 0.303549099248, 0.10183998569...   \n",
       "177888  [-0.390038985759, 0.0567329889163, 0.371367026...   \n",
       "\n",
       "                                           paragraph_CBOW  \n",
       "530192  [1.04178700969, 0.649680987, 0.633059997112, -...  \n",
       "77501   [8.48787346703, 9.09795231628, -1.21728977765,...  \n",
       "198858  [-0.69690399617, -0.88491801545, -2.5799840046...  \n",
       "195387  [2.70971485808, 24.6431179714, -21.5583597224,...  \n",
       "177888  [-3.37157545811, 5.95376241195, -9.73813020345...  "
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training pairs: 624290\n",
      "Number of testing pairs: 85131\n"
     ]
    }
   ],
   "source": [
    "# Prepare data\n",
    "\n",
    "# shuffle df\n",
    "df = df.reindex(np.random.permutation(df.index))\n",
    "\n",
    "# set number of train and test instances\n",
    "num_train = int(df.shape[0] * 0.88)\n",
    "num_test = df.shape[0] - num_train                 \n",
    "print(\"Number of training pairs: %i\"%(num_train))\n",
    "print(\"Number of testing pairs: %i\"%(num_test))\n",
    "\n",
    "# init data data arrays dim = num_train x (query, paragr) x embedding length\n",
    "X_train = np.zeros([num_train, 2, 300])\n",
    "X_test  = np.zeros([num_test, 2, 300])\n",
    "Y_train = np.zeros([num_train]) \n",
    "Y_test = np.zeros([num_test])\n",
    "\n",
    "# format data \n",
    "b = [a[None,:] for a in list(df['query_CBOW'].values)]\n",
    "query_feats = np.concatenate(b, axis=0)\n",
    "\n",
    "b = [a[None,:] for a in list(df['paragraph_CBOW'].values)]\n",
    "paragraph_feats = np.concatenate(b, axis=0)\n",
    "\n",
    "# fill data arrays with features\n",
    "X_train[:,0,:] = query_feats[:num_train]\n",
    "X_train[:,1,:] = paragraph_feats[:num_train]\n",
    "Y_train = df[:num_train]['rel_label'].values\n",
    "            \n",
    "X_test[:,0,:] = query_feats[num_train:]\n",
    "X_test[:,1,:] = paragraph_feats[num_train:]\n",
    "Y_test = df[num_train:]['rel_label'].values\n",
    "\n",
    "# remove useless variables\n",
    "del b\n",
    "del query_feats\n",
    "del paragraph_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Expected int32, got list containing Tensors of type '_Message' instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-167-6041938111e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mxx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0myy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mxx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0myy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'out'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vincentchabot/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.pyc\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(concat_dim, values, name)\u001b[0m\n\u001b[1;32m    865\u001b[0m       ops.convert_to_tensor(concat_dim,\n\u001b[1;32m    866\u001b[0m                             \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"concat_dim\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 867\u001b[0;31m                             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    868\u001b[0m                             ).assert_is_compatible_with(tensor_shape.scalar())\n\u001b[1;32m    869\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vincentchabot/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype)\u001b[0m\n\u001b[1;32m    655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 657\u001b[0;31m           \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vincentchabot/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/constant_op.pyc\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    178\u001b[0m                                          as_ref=False):\n\u001b[1;32m    179\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vincentchabot/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/constant_op.pyc\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    161\u001b[0m   \u001b[0mtensor_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m   tensor_value.tensor.CopyFrom(\n\u001b[0;32m--> 163\u001b[0;31m       tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape))\n\u001b[0m\u001b[1;32m    164\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m   const_tensor = g.create_op(\n",
      "\u001b[0;32m/Users/vincentchabot/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/tensor_util.pyc\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape)\u001b[0m\n\u001b[1;32m    351\u001b[0m       \u001b[0mnparray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp_dt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m       \u001b[0m_AssertCompatible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m       \u001b[0mnparray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp_dt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m       \u001b[0;31m# check to them.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vincentchabot/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/tensor_util.pyc\u001b[0m in \u001b[0;36m_AssertCompatible\u001b[0;34m(values, dtype)\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m       raise TypeError(\"Expected %s, got %s of type '%s' instead.\" %\n\u001b[0;32m--> 290\u001b[0;31m                       (dtype.name, repr(mismatch), type(mismatch).__name__))\n\u001b[0m\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Expected int32, got list containing Tensors of type '_Message' instead."
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float64, shape=300)\n",
    "y = tf.placeholder(tf.float64, shape=300)\n",
    "xx = tf.placeholder(tf.float64, shape=[300,2])\n",
    "yy = tf.placeholder(tf.float64, shape=[300,2])\n",
    "xx = tf.concat([x, x], 1)\n",
    "yy = tf.concat([y, y], 1)\n",
    "out = tf.reduce_sum(tf.mul(yy, tf.reduce_sum(tf.mul(weights['out'], xx))  ) )\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    q = X_train[0,0,:] \n",
    "    p = X_train[0,1,:]\n",
    "    print(sess.run(out, feed_dict={x: q, y: p}))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nq = tf.placeholder(tf.float64, shape = n_input)\\np = tf.placeholder(tf.float64, shape = n_input)\\ny = tf.placeholder(tf.float64, shape = n_classes) \\n'"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parameters\n",
    "training_epochs = 10\n",
    "batch_size = 100\n",
    "display_step = 1\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 300\n",
    "n_classes = 2\n",
    "\n",
    "# tf Graph input\n",
    "\n",
    "q = tf.placeholder(\"float64\", [None, n_input, n_classes])\n",
    "p = tf.placeholder(\"float64\", [None, n_input, n_classes])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])\n",
    "'''\n",
    "q = tf.placeholder(tf.float64, shape = n_input)\n",
    "p = tf.placeholder(tf.float64, shape = n_input)\n",
    "y = tf.placeholder(tf.float64, shape = n_classes) \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create model\n",
    "def bilinar(q, p, weights):\n",
    "    # Hidden layer with RELU activation\n",
    "    out = [tf.reduce_sum(tf.mul(q, tf.reduce_sum(tf.mul(weights['out'], p))  ) )]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Placeholder_95:0' shape=(?, 2) dtype=float32>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Dimensions must be equal, but are 2 and 300",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-142-c0bae1856af8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Construct model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbilinar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Define loss and optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-139-16890e191054>\u001b[0m in \u001b[0;36mbilinar\u001b[0;34m(q, p, weights)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbilinar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# Hidden layer with RELU activation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'out'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vincentchabot/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/gen_math_ops.pyc\u001b[0m in \u001b[0;36mmul\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   1517\u001b[0m     \u001b[0mA\u001b[0m \u001b[0;34m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mHas\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0;34m`\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1518\u001b[0m   \"\"\"\n\u001b[0;32m-> 1519\u001b[0;31m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op_def_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Mul\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1520\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vincentchabot/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.pyc\u001b[0m in \u001b[0;36mapply_op\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    747\u001b[0m           op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    748\u001b[0m                            \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 749\u001b[0;31m                            op_def=op_def)\n\u001b[0m\u001b[1;32m    750\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m           return _Restructure(ops.convert_n_to_tensor(outputs),\n",
      "\u001b[0;32m/Users/vincentchabot/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   2380\u001b[0m                     original_op=self._default_original_op, op_def=op_def)\n\u001b[1;32m   2381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2382\u001b[0;31m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2383\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2384\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vincentchabot/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1781\u001b[0m       raise RuntimeError(\"No shape function registered for standard op: %s\"\n\u001b[1;32m   1782\u001b[0m                          % op.type)\n\u001b[0;32m-> 1783\u001b[0;31m   \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1784\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m     raise RuntimeError(\n",
      "\u001b[0;32m/Users/vincentchabot/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/common_shapes.pyc\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[0;34m(op, input_tensors_needed, debug_python_shape_fn)\u001b[0m\n\u001b[1;32m    594\u001b[0m                                                              status)\n\u001b[1;32m    595\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m   \u001b[0;31m# Convert TensorShapeProto values in output_shapes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Dimensions must be equal, but are 2 and 300"
     ]
    }
   ],
   "source": [
    "# Store layers weight & bias\n",
    "weights = {'out': tf.Variable(tf.random_normal([n_input, n_input, n_classes],dtype=tf.float64))}\n",
    "\n",
    "# Construct model\n",
    "pred = bilinar(q, p, weights)\n",
    "\n",
    "# Define loss and optimizer\n",
    "#cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "cost = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=pred, labels=y)\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (300,) for Tensor u'Placeholder_37:0', which has shape '(?, 300)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-93-592daf3eb6d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;31m# Run optimization op (backprop) and cost op (to get loss value)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_q\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0;31m# Compute average loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mavg_cost\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtotal_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vincentchabot/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    715\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 717\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    718\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vincentchabot/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    892\u001b[0m                 \u001b[0;34m'Cannot feed value of shape %r for Tensor %r, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m                 \u001b[0;34m'which has shape %r'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m                 % (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m    895\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (300,) for Tensor u'Placeholder_37:0', which has shape '(?, 300)'"
     ]
    }
   ],
   "source": [
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.\n",
    "        \n",
    "        total_batch = 5\n",
    "        \n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            \n",
    "            batch_q = np.transpose(X_train[0,0,:]) #tf.constant(X_train[:100][0])\n",
    "            batch_p = np.transpose(X_train[0,1,:]) #tf.constant(X_train[:100][1])\n",
    "            batch_y = np.transpose(Y_train[0]) #tf.constant(Y_train[:100])\n",
    "            '''\n",
    "            batch_q = X_train[0,0,:] #tf.constant(X_train[:100][0])\n",
    "            batch_p = X_train[0,1,:] #tf.constant(X_train[:100][1])\n",
    "            batch_y = Y_train[0] #tf.constant(Y_train[:100])\n",
    "            '''\n",
    "              \n",
    "            # Run optimization op (backprop) and cost op (to get loss value)\n",
    "            _, c = sess.run([optimizer, cost], feed_dict={q: batch_q, p: batch_p, y: batch_y})\n",
    "            # Compute average loss\n",
    "            avg_cost += c / total_batch\n",
    "        # Display logs per epoch step\n",
    "        if epoch % display_step == 0:\n",
    "            print \"Epoch:\", '%04d' % (epoch+1), \"cost=\", \\\n",
    "                \"{:.9f}\".format(avg_cost)\n",
    "    print \"Optimization Finished!\"\n",
    "\n",
    "    # Test model\n",
    "    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "    # Calculate accuracy\n",
    "    #accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    #print \"Accuracy:\", accuracy.eval({x: mnist.test.images, y: mnist.test.labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Lambda, merge, BatchNormalization, Activation, Input, Merge\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "def euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    return K.sqrt(K.sum(K.square(x - y), axis=1, keepdims=True))\n",
    "\n",
    "def eucl_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0], 1)\n",
    "\n",
    "def cosine_distance(vests):\n",
    "    x, y = vests\n",
    "    x = K.l2_normalize(x, axis=-1)\n",
    "    y = K.l2_normalize(y, axis=-1)\n",
    "    return -K.mean(x * y, axis=-1, keepdims=True)\n",
    "\n",
    "def cos_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0],1)\n",
    "\n",
    "def contrastive_loss(y_true, y_pred):\n",
    "    '''Contrastive loss from Hadsell-et-al.'06\n",
    "    http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    '''\n",
    "    margin = 1\n",
    "    return K.mean(y_true * K.square(y_pred) + (1 - y_true) * K.square(K.maximum(margin - y_pred, 0)))\n",
    "\n",
    "\n",
    "def create_base_network(input_dim):\n",
    "    '''\n",
    "    Base network for feature extraction.\n",
    "    '''\n",
    "    input = Input(shape=(input_dim, ))\n",
    "    dense1 = Dense(128)(input)\n",
    "    bn1 = BatchNormalization(mode=2)(dense1)\n",
    "    relu1 = Activation('relu')(bn1)\n",
    "\n",
    "    dense2 = Dense(128)(relu1)\n",
    "    bn2 = BatchNormalization(mode=2)(dense2)\n",
    "    res2 = merge([relu1, bn2], mode='sum')\n",
    "    relu2 = Activation('relu')(res2)    \n",
    "\n",
    "    dense3 = Dense(128)(relu2)\n",
    "    bn3 = BatchNormalization(mode=2)(dense3)\n",
    "    res3 = Merge(mode='sum')([relu2, bn3])\n",
    "    relu3 = Activation('relu')(res3)  \n",
    "    \n",
    "    feats = merge([relu3, relu2, relu1], mode='concat')\n",
    "    bn4 = BatchNormalization(mode=2)(feats)\n",
    "\n",
    "    model = Model(input=input, output=bn4)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def compute_accuracy(predictions, labels):\n",
    "    '''\n",
    "    Compute classification accuracy with a fixed threshold on distances.\n",
    "    '''\n",
    "    return labels[predictions.ravel() < 0.5].mean()\n",
    "\n",
    "def create_network(input_dim):\n",
    "    # network definition\n",
    "    base_network = create_base_network(input_dim)\n",
    "    \n",
    "    input_a = Input(shape=(input_dim,))\n",
    "    input_b = Input(shape=(input_dim,))\n",
    "    \n",
    "    # because we re-use the same instance `base_network`,\n",
    "    # the weights of the network\n",
    "    # will be shared across the two branches\n",
    "    processed_a = base_network(input_a)\n",
    "    processed_b = base_network(input_b)\n",
    "    \n",
    "    distance = Lambda(euclidean_distance, output_shape=eucl_dist_output_shape)([processed_a, processed_b])\n",
    "    \n",
    "    model = Model(input=[input_a, input_b], output=distance)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "X_train_norm = np.zeros(X_train.shape)\n",
    "X_train_norm[:,0,:] = preprocessing.normalize(X_train[:,0,:])\n",
    "X_train_norm[:,1,:] = preprocessing.normalize(X_train[:,1,:])\n",
    "X_test_norm = np.zeros(X_test.shape)\n",
    "X_test_norm[:,0,:] = preprocessing.normalize(X_test[:,0,:])\n",
    "X_test_norm[:,1,:] = preprocessing.normalize(X_test[:,1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 153 samples, validate on 21 samples\n",
      "Epoch 1/1\n",
      "153/153 [==============================] - 3s - loss: 693.7363 - val_loss: 686.9468\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Model' object has no attribute 'predict_classes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-138-340636c87531>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# compute final accuracy on training and test sets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_test_norm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_norm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Normalize X_test ?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mte_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Model' object has no attribute 'predict_classes'"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "# from siamese import *\n",
    "from keras.optimizers import RMSprop, SGD, Adam\n",
    "net = create_network(300)\n",
    "\n",
    "# train\n",
    "#optimizer = SGD(lr=1, momentum=0.8, nesterov=True, decay=0.004)\n",
    "optimizer = Adam(lr=0.001)\n",
    "net.compile(loss=contrastive_loss, optimizer=optimizer)\n",
    "\n",
    "for epoch in range(100):\n",
    "    net.fit([X_train_norm[:,0,:], X_train_norm[:,1,:]], Y_train, # Normalize X_train ?\n",
    "          validation_data=([X_test_norm[:,0,:], X_test_norm[:,1,:]], Y_test), # Normalize X_test ?\n",
    "          batch_size=128, nb_epoch=1, shuffle=True, )\n",
    "    \n",
    "    # compute final accuracy on training and test sets\n",
    "    pred = net.predict_classes([X_test_norm[:,0,:], X_test_norm[:,1,:]], batch_size=128) # Normalize X_test ?\n",
    "    te_acc = compute_accuracy(pred, Y_test)\n",
    "    \n",
    "    pred_train = net.predict_classes([X_train_norm[:,0,:], X_train_norm[:,1,:]], batch_size=128) # Normalize X_test ?\n",
    "    tr_acc = compute_accuracy(pred_train, Y_train)\n",
    "    \n",
    "    print(tr_acc)\n",
    "    \n",
    "print('* Accuracy on training set: %0.2f%%' % (100 * tr_acc))\n",
    "print('* Accuracy on test set: %0.2f%%' % (100 * te_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "<type 'numpy.ndarray'>\n",
      "<type 'numpy.ndarray'>\n",
      "(1,)\n",
      "<type 'numpy.ndarray'>\n",
      "(21,)\n"
     ]
    }
   ],
   "source": [
    "print(te_acc)\n",
    "print(type(pred[:][0]))\n",
    "print(type(pred[:][0]))\n",
    "print(pred[:][0].shape)\n",
    "print(type(Y_test))\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred = pred.reshape(Y_test.shape).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.39133286],\n",
       "       [  4.0400672 ],\n",
       "       [  6.06718016],\n",
       "       [  4.46551609],\n",
       "       [  6.1903801 ],\n",
       "       [  7.62450457],\n",
       "       [  5.38022614],\n",
       "       [  4.95393896],\n",
       "       [  4.19205475],\n",
       "       [  4.41008043],\n",
       "       [  4.86572075],\n",
       "       [  3.5670836 ],\n",
       "       [  4.99328041],\n",
       "       [  3.69709849],\n",
       "       [  7.10036135],\n",
       "       [  4.63419914],\n",
       "       [  9.24658585],\n",
       "       [  3.99168658],\n",
       "       [  3.63978744],\n",
       "       [ 11.5053587 ],\n",
       "       [  4.38359833],\n",
       "       [  7.02809   ],\n",
       "       [  4.70760202],\n",
       "       [  5.80150318],\n",
       "       [  5.34516954],\n",
       "       [  4.79439926],\n",
       "       [  4.41186476],\n",
       "       [  3.2565546 ],\n",
       "       [  3.69785547],\n",
       "       [  9.01588917],\n",
       "       [  4.04520607],\n",
       "       [  3.79550385],\n",
       "       [ 16.75971603],\n",
       "       [  4.82048416],\n",
       "       [  6.22091484],\n",
       "       [  3.45065451],\n",
       "       [  8.84228706],\n",
       "       [  8.85808849],\n",
       "       [  3.87091208],\n",
       "       [  3.47586226],\n",
       "       [  7.68869972],\n",
       "       [  4.40386724],\n",
       "       [  6.25794458],\n",
       "       [  9.05072689],\n",
       "       [  6.63338327],\n",
       "       [  4.4786911 ],\n",
       "       [  5.81221533],\n",
       "       [  4.28389359],\n",
       "       [  4.20125198],\n",
       "       [ 14.85985088],\n",
       "       [  4.76283312],\n",
       "       [  5.5817709 ],\n",
       "       [  4.5445714 ],\n",
       "       [  6.06480455],\n",
       "       [  7.49605751],\n",
       "       [  6.77237082],\n",
       "       [  8.9117918 ],\n",
       "       [  3.41670418],\n",
       "       [  5.01860285],\n",
       "       [  3.17040825],\n",
       "       [  3.39317298],\n",
       "       [  3.97642732],\n",
       "       [  5.75808764],\n",
       "       [  4.00403214],\n",
       "       [  5.72837925],\n",
       "       [  5.77591705],\n",
       "       [  6.48481035],\n",
       "       [  4.97182035],\n",
       "       [  4.93823385],\n",
       "       [  4.00008917],\n",
       "       [  4.90302563],\n",
       "       [  4.00539923],\n",
       "       [  7.14030647],\n",
       "       [  5.04575491],\n",
       "       [ 10.14478111],\n",
       "       [  4.33161926],\n",
       "       [  5.30812931],\n",
       "       [  6.4644742 ],\n",
       "       [  3.65253711],\n",
       "       [  8.00604248],\n",
       "       [  4.71059656],\n",
       "       [  4.05962896],\n",
       "       [  3.21765184],\n",
       "       [  7.28804874],\n",
       "       [  4.27625751],\n",
       "       [  5.21593952],\n",
       "       [  4.07016706],\n",
       "       [  3.5795095 ],\n",
       "       [  7.86966658],\n",
       "       [  4.50017118],\n",
       "       [  4.87083578],\n",
       "       [  3.40612173],\n",
       "       [  4.92548084],\n",
       "       [  3.22338581],\n",
       "       [  5.16911936],\n",
       "       [  6.53335619],\n",
       "       [  6.29417419],\n",
       "       [  9.67285442],\n",
       "       [ 10.05491924],\n",
       "       [  5.60608673],\n",
       "       [  7.44313622],\n",
       "       [  6.77003098],\n",
       "       [  6.65970325],\n",
       "       [  7.33420372],\n",
       "       [ 10.68490505],\n",
       "       [  3.97123885],\n",
       "       [  8.04471779],\n",
       "       [  4.45277596],\n",
       "       [  6.72660208],\n",
       "       [  7.2041173 ],\n",
       "       [  3.69424748],\n",
       "       [  4.78971481],\n",
       "       [ 11.29440784],\n",
       "       [  4.13880777],\n",
       "       [  4.50512791],\n",
       "       [  6.20735598],\n",
       "       [  5.51314545],\n",
       "       [  6.53767729],\n",
       "       [  4.2003932 ],\n",
       "       [  4.00286436],\n",
       "       [  3.88435745],\n",
       "       [  3.42284417],\n",
       "       [  3.21674252],\n",
       "       [  4.10409498],\n",
       "       [  6.29631472],\n",
       "       [  5.50169373],\n",
       "       [  4.20297718],\n",
       "       [  4.6456399 ],\n",
       "       [  7.22283411],\n",
       "       [  8.94139862],\n",
       "       [  4.52005577],\n",
       "       [  6.55248022],\n",
       "       [  5.47621346],\n",
       "       [  5.26481199],\n",
       "       [  7.97822428],\n",
       "       [  3.86134076],\n",
       "       [  4.3112731 ],\n",
       "       [  6.39206839],\n",
       "       [  3.89100742],\n",
       "       [  5.34724379],\n",
       "       [  4.63127422],\n",
       "       [  6.6705904 ],\n",
       "       [  5.48826599],\n",
       "       [  8.95204926],\n",
       "       [  4.83027554],\n",
       "       [ 13.12535763],\n",
       "       [  5.7527194 ],\n",
       "       [  5.32700872],\n",
       "       [  5.14304733],\n",
       "       [  4.64656353],\n",
       "       [  7.66469145],\n",
       "       [  8.49621105],\n",
       "       [  5.86496735]], dtype=float32)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred = pred.reshape(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_accuracy(predictions, labels):\n",
    "    '''\n",
    "    Compute classification accuracy with a fixed threshold on distances.\n",
    "    '''\n",
    "    return labels[predictions.ravel() < 0.5].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_accuracy(pred, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 21.53193092,  40.35143661,  12.72819614,  17.25185585,\n",
       "        10.99982071,  11.09136677,  11.42963505,  12.64740086,\n",
       "        16.93758392,  34.72384262,  21.15718269,  11.68271637,\n",
       "        10.79737282,  10.14541817,  14.79070282,  26.73973083,\n",
       "        11.13249588,  13.70429611,  45.7140274 ,  38.70048141,  25.32180977], dtype=float32)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 1)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_test = Y_test.reshape((21,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train[pred_train.ravel() < 0.5].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train[pred_train.ravel() < 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True, False,  True, False, False, False,  True, False,\n",
       "        True, False,  True,  True,  True,  True,  True, False,  True,\n",
       "        True, False, False, False,  True, False,  True, False, False,\n",
       "       False, False, False,  True,  True, False, False, False,  True,\n",
       "       False, False,  True,  True, False,  True, False, False, False,\n",
       "        True, False,  True,  True, False,  True, False,  True, False,\n",
       "       False, False, False,  True,  True,  True,  True, False, False,\n",
       "        True, False,  True, False, False,  True, False,  True,  True,\n",
       "       False,  True, False,  True, False, False,  True, False,  True,\n",
       "        True, False, False, False,  True, False,  True, False,  True,\n",
       "        True,  True, False,  True, False,  True, False, False, False,\n",
       "        True, False, False, False, False, False,  True, False,  True,\n",
       "        True, False, False, False, False,  True,  True, False, False,\n",
       "       False,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "        True,  True, False, False, False, False, False, False, False,\n",
       "       False, False, False,  True, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False], dtype=bool)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_train.ravel()< 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
